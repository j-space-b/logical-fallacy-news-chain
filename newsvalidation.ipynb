{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51359d1",
   "metadata": {},
   "source": [
    "# Logical fallacy extraction from live news articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2faa5",
   "metadata": {},
   "source": [
    "### What is this? \n",
    "This script returns any logical fallaces found in news articles, so you can feel enlightened and empowered and not manipulated\n",
    "\n",
    "### How does this work?\n",
    "1. You specify a topic to search the news on\n",
    "2. Script uses the Google News API to return a list of articles on a topic from the last 7 days\n",
    "2. Extracts the news text using Beautiful Soup\n",
    "3. Creates a Sequential Chain using LangChain and OpenAI to analyze and return any logical fallacies found \n",
    "\n",
    "### How are logical fallacies defined?\n",
    "This paper on Arxiv describes 19 categories found since Aristotle's original 13 - incorporated for RAG using OpenAI's embeddings model and FAISS vector db for quick retreival and analysis\n",
    "<br> https://arxiv.org/pdf/2212.07425.pdf\n",
    "\n",
    "### How do I deploy this on my machine?\n",
    "Either run this notebook, or out of this same directory run ```streamlit run newsvalidation.py``` to open GUI courtesy of streamlit\n",
    "\n",
    "### Requirements\n",
    "Use your venv and requirements.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24c277bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys \n",
    "import openai \n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "serper_api_key  = os.environ['SERPER_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f27cf068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import faiss\n",
    "import json\n",
    "from langchain import OpenAI, VectorDBQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader, JSONLoader, UnstructuredFileLoader, WebBaseLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import LLMChain, SequentialChain, RetrievalQA\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.schema import Document\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import streamlit as st, tiktoken \n",
    "from unstructured.cleaners.core import clean_extra_whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5ecea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.retrievers import TimeWeightedVectorStoreRetriever\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9822a3f4",
   "metadata": {},
   "source": [
    "## Load logical fallacies to memory\n",
    "arxiv > dict > faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15ee0edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 19 logical fallacies\n",
    "# source of extract: \"https://arxiv.org/pdf/2212.07425.pdf\n",
    "# will be used to evaluate results when using this as a datasource rather than the pdf \n",
    "\n",
    "fallacies = {\n",
    "    \"Logical Fallacy Name\": [\"Adhominem\",\"Adpopulum\",\"Appeal to Emotion\",\"Fallacy of Extension\",\n",
    "                        \"Intentional Fallacy\",\"False Causality\",\"False Dilemma\",\"Hasty Generalization\",\n",
    "                        \"Illogical Arrangement\",\"Fallacy of Credibility\",\"Circular Reasoning\",\n",
    "                        \"Begging the Question\",\"Trick Question\",\"Overapplying\",\"Equivocation\",\"Amphiboly\",\n",
    "                        \"Word Emphasis\",\"Composition\",\"Division\"],\n",
    "    \"Description\": [\"attacks on the character or personal traits of the person making an argument rather than addressing the actual argument and evidence\",\n",
    "                   \"the fallacy that something must be true or correct simply because many people believe it or do it, without actual facts or evidence to support\",\n",
    "                   \"an attempt to win support for an argument by exploiting or manipulating people's emotions rather than using facts and reason\",\n",
    "                   \"making broad, sweeping generalizations and extending the implications of an argument far beyond what the initial premises support\",\n",
    "                   \"falsely supporting a conclusion by claiming to understand an author or creator's subconscious intentions without clear evidence\",\n",
    "                   \"jumping to conclusions about causation between events or circumstances without adequate evidence to infer a causal relationship\",\n",
    "                   \"presenting only two possible options or sides to a situation when there are clearly other alternatives that have not been considered or addressed\",\n",
    "                   \"making a broad inference or generalization to situations, people, or circumstances that are not sufficiently similar based on a specific example or limited evidence\",\n",
    "                   \"constructing an argument in a flawed, illogical way, so the premises do not connect to or lead to the conclusion properly\",\n",
    "                   \"dismissing or attacking the credibility of the person making an argument rather than directly addressing the argument itself\",\n",
    "                 \"supporting a premise by simply repeating the premise as the conclusion without giving actual proof or evidence\",\n",
    "                  \"restating the conclusion of an argument as a premise without providing actual support for the conclusion in the first place\",\n",
    "                   \"asking a question that contains or assumes information that has not been proven or substantiated\",\n",
    "                   \"applying a general rule or generalization to a specific case it was not meant to apply to\",\n",
    "                   \"using the same word or phrase in two different senses or contexts within an argument\",\n",
    "                   \"constructing sentences such that the grammar or structure is ambiguous, leading to multiple interpretations\",\n",
    "                   \"shifting the emphasis of a word or phrase to give it a different meaning than intended\",\n",
    "                   \"erroneously inferring that something is true of the whole based on the fact that it is true of some part or parts\",\n",
    "                   \"erroneously inferring that something is true of the parts based on the fact that it is true of the whole\"]\n",
    "}\n",
    "json_str = json.dumps(fallacies, indent=4)\n",
    "\n",
    "\n",
    "with open(\"fallacies.json\", \"w\") as json_file:\n",
    "    json_file.write(json_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "253a04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dict as JSON - could not quickly find an obvious method to load dict as same format that loader.load expects\n",
    "\n",
    "loader = JSONLoader(\n",
    "    file_path='./fallacies.json',\n",
    "    jq_schema='.',\n",
    "    text_content=False)\n",
    "\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "86b156bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split dictionary using same methodology as the pdf - similar amount of docs from splits as the PDF\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo', openai.api_key=open_api_key)\n",
    "chunk_size=50\n",
    "chunk_overlap=10\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len\n",
    ")\n",
    "docs2 = text_splitter.split_documents(data)\n",
    "len(docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9c749fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup faiss retreiver and save for later references\n",
    "\n",
    "db2 = FAISS.from_documents(docs2, embeddings)\n",
    "retriever2 = db2.as_retriever(search_kwargs={\"k\":2})\n",
    "model2 = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever2)\n",
    "save_directory2 = \"FallacyDict\"\n",
    "db2.save_local(save_directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b9d13438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary categories of logical fallacies are:\n",
      "\n",
      "1. Ad Hominem: This fallacy involves attacks on the character or personal traits of the person making an argument rather than addressing the actual argument and evidence.\n",
      "\n",
      "2. Ad Populum: This is the fallacy that something must be true or correct simply because many people believe it or do it, without actual facts or evidence to support.\n",
      "\n",
      "3. Appeal to Emotion: This fallacy is an attempt to win support for an argument by exploiting or manipulating people's emotions rather than using facts and reason.\n",
      "\n",
      "4. Fallacy of Extension: This fallacy involves making broad, sweeping generalizations and extending the implications of an argument far beyond what the initial premises support.\n",
      "\n",
      "5. Intentional Fallacy: This fallacy involves falsely supporting a conclusion by claiming to understand an author or creator's subconscious intentions without clear evidence.\n",
      "\n",
      "6. False Causality: This fallacy involves jumping to conclusions about causation between events or circumstances without adequate evidence to infer a causal relationship.\n",
      "\n",
      "7. False Dilemma: This fallacy involves presenting only two possible options or sides to a situation when there are clearly other alternatives that have not been considered or addressed.\n",
      "\n",
      "8. Hasty Generalization: This fallacy involves making a broad inference or generalization to situations, people, or circumstances that are not sufficiently similar based on a specific example or limited evidence.\n",
      "\n",
      "9. Illogical Arrangement: This fallacy involves constructing an argument in a flawed, illogical way, so the premises do not connect to or lead to the conclusion properly.\n",
      "\n",
      "10. Fallacy of Credibility: This fallacy involves dismissing or attacking the credibility of the person making an argument rather than directly addressing the argument itself.\n",
      "\n",
      "11. Circular Reasoning: This fallacy involves supporting a premise by simply repeating the premise as the conclusion without giving actual proof or evidence.\n",
      "\n",
      "12. Begging the Question: This fallacy involves restating the conclusion of an argument as a premise without providing actual support for the conclusion in the first place.\n",
      "\n",
      "13. Trick Question: This fallacy involves asking a question that contains or assumes information that has not been proven or substantiated.\n",
      "\n",
      "14. Overapplying: This fallacy involves applying a general rule or generalization to a specific case it was not meant to apply to.\n",
      "\n",
      "15. Equivocation: This fallacy involves using the same word or phrase in two different senses or contexts within an argument.\n",
      "\n",
      "16. Amphiboly: This fallacy involves constructing sentences such that the grammar or structure is ambiguous, leading to multiple interpretations.\n",
      "\n",
      "17. Word Emphasis: This fallacy involves shifting the emphasis of a word or phrase to give it a different meaning than intended.\n",
      "\n",
      "18. Composition: This fallacy involves erroneously inferring that something is true of the whole based on the fact that it is true of some part or parts.\n",
      "\n",
      "19. Division: This fallacy involves erroneously inferring that something is true of the parts based on the fact that it is true of the whole.\n"
     ]
    }
   ],
   "source": [
    "# Test faiss call \n",
    "\n",
    "query = 'list the primary categories and subcategories of logical fallacies and define each one'\n",
    "response = model2({\"query\":query}, return_only_outputs=True)\n",
    "f_results = model2.run(query)\n",
    "print(f_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f1509",
   "metadata": {},
   "source": [
    "## Call API for News URLs by way of search terms or API\n",
    "Using SerperAPI, search term results ranked by relevancy to key words in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2f9d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search news - setting up the republican debate from this past week, using 3 articles to test\n",
    "# this is the input textfield in streamlit but hardcoding here for demo in ipynb file \n",
    "\n",
    "search_query = 'covid'\n",
    "num_results = 3\n",
    "\n",
    "search = GoogleSerperAPIWrapper(type=\"news\", tbs=\"qdr:w1\", serper_api_key=serper_api_key)\n",
    "\n",
    "try:\n",
    "    result_dict = search.results(search_query)\n",
    "    for i, item in zip(range(num_results), result_dict['news']):\n",
    "        url = item.get('link','N/A') \n",
    "        if url == 'N/A':\n",
    "            continue  \n",
    "        loader = WebBaseLoader(url) # using bs4 \n",
    "        try:\n",
    "            datanews = loader.load()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {item['link']}, exception: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching search results, exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4cc2b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fallacy text\n",
    "\n",
    "result_text = \"\"\n",
    "\n",
    "for fallacy_name, description in zip(fallacies['Logical Fallacy Name'], fallacies['Description']):\n",
    "    result_text += f\"Logical Fallacy Name: {fallacy_name}\\n\"\n",
    "    result_text += f\"Description: {description}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4155b506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize for embeddings if/where needed\n",
    "chunk_size=50\n",
    "chunk_overlap=10\n",
    "\n",
    "text_splitter_news = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap, separators=[\" \", \",\", \"\\n\"]\n",
    "    )\n",
    "\n",
    "news = text_splitter_news.split_documents(datanews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f6b33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model using OpenAI \n",
    "embeddings_model3 = OpenAIEmbeddings()\n",
    "embedding_size = 1536\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore3 = FAISS(embeddings_model3.embed_query, index, InMemoryDocstore({}), {})\n",
    "retriever3 = TimeWeightedVectorStoreRetriever(vectorstore=vectorstore3, decay_rate=.999999, k=2)\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever3) # memory might not be needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bd2c59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Chain 1: Summarize any possible logical fallacies in the text of the article\n",
    "\n",
    "template1 = \"\"\"You are a communications expert who speaks nothing but truth and logic and is \\\n",
    "extremely clear for a wide audience.  Given a full news article, your job is to summarize \\\n",
    "it accurately and with brevity in one sentence, then find any logical fallacies that \\\n",
    "may exist and return examples in no more than 1 sentence per logical fallacy found.  \\\n",
    "If more than one logical fallacies are found, return the top 2, in order of logical strength, \\\n",
    "unless no logical fallacies are found, in which then state no strong logical fallacies are clearly evident. \\\n",
    "Article: {datanews} \\\n",
    "Communications expert: \n",
    "Summary:\"\"\"\n",
    "prompt_template1 = PromptTemplate(input_variables=[\"datanews\"], template=template1)\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt_template1, output_key='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9e78da40",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Chain 2: Analyze the implications of any logical fallacies in the article in relation to the article summary\n",
    "\n",
    "template2 = \"\"\"You are an engaging professor who only speaks with truth and sound logic \\\n",
    "while clearly conveying a point in as few words as possible.  Given the text of a news article as defined, if the title reads 'Access Denied' then state no access \\\n",
    "to the article is available. If the title does not read 'Access Denied', then create two outputs: Analysis and Counterfactual. \\\n",
    "For the Analysis output, it will be three parts.  The first part is labeled 'Summary' and returns {summary}.  The second part is labeled 'Analysis' and is two sentences.  First, you need \\\n",
    "to return the top ranked logical fallacy in the article, among any logical fallacies that may exist, ranked by order of logical strength, \\\n",
    "described with brevity in one sentence and confirming this logical fallacy is correct by extracting factual evidence \\\n",
    "from the article text, then finally referencing the extracted fact in the description. Be sure to state the strongest logical fallacy might not be strong, \\\n",
    "so is only to consider. Create the second sentence of the Analysis output by stating why this fallacy might be dangerous to the public or \\\n",
    "especially misleading in the context of the news article, with respect to how other readers could react. \\\n",
    "The third part is labeled 'Theoretical Counterfactual', explain any counterfactuals to the summary of the article ({summary}) that could hypothetically be true, \\\n",
    "based on logic and the limited facts presented in the article.  If more than one counterfactuals exist, only return  \\\n",
    "the top ranked counterfactual, ranked in order of logical strength and feasibility, described with brevity in 1 sentence. \\ \n",
    "Professor: \\\n",
    "Summary: {summary}\\\n",
    "Analysis: \\ \n",
    "Theoretical Counterfactual: \"\"\"\n",
    "prompt_template2 = PromptTemplate(input_variables=[\"summary\"], template=template2)\n",
    "chain2 = LLMChain(llm=llm, prompt=prompt_template2, output_key='analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7c86644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "If the COVID-19 virus mutates significantly, the current vaccines may not provide the same level of protection as they do now.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "If the vaccines were not updated to better protect against the currently circulating variants, it is possible that the efficacy of the vaccines could decrease, leading to a potential increase in COVID-19 cases.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Analysis: \n",
      "The strongest logical fallacy in the article is the appeal to authority, as it relies on the CDC and FDA's authority to validate the vaccine's effectiveness without providing specific data or studies. This fallacy could be misleading to the public as it may lead them to believe that the vaccine's effectiveness is universally accepted and uncontested, potentially discouraging further research or questioning.\n",
      "\n",
      "Theoretical Counterfactual: \n",
      "A possible counterfactual could be that if other health organizations or independent studies did not support the CDC's recommendation, the HHS Secretary Xavier Becerra might not have endorsed the updated COVID-19 vaccines.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Given the lack of content, a potential counterfactual could be that the article contains relevant and insightful information, but it is inaccessible due to technical requirements.\n"
     ]
    }
   ],
   "source": [
    "# search news with input string\n",
    "# this is the input textfield in streamlit but hardcoding here for demo in ipynb file \n",
    "\n",
    "search_query = 'covid'\n",
    "num_results = 4\n",
    "\n",
    "\n",
    "search = GoogleSerperAPIWrapper(type=\"news\",tbs=\"qdr:w1\", serper_api_key=serper_api_key)\n",
    "\n",
    "try:\n",
    "    result_dict = search.results(search_query)\n",
    "    for i, item in zip(range(num_results), result_dict['news']):\n",
    "        url = item.get('link','N/A') \n",
    "        if url == 'N/A':\n",
    "            continue  \n",
    "        loader = WebBaseLoader(url) # bs4 \n",
    "        try:\n",
    "            datanews = loader.load()\n",
    "            overall_chain1 = SequentialChain(chains=[chain1, chain2],\n",
    "                input_variables=[\"datanews\"],\n",
    "                output_variables=[\"analysis\"],\n",
    "                verbose=True)\n",
    "            first = (overall_chain1({\"datanews\":datanews}))\n",
    "            analysis = first['analysis']\n",
    "            print(analysis)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {item['link']}, exception: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching search results, exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "19f7521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replicating above functionality but using Streamlit for input\n",
    "st.subheader('Enter search terms:')\n",
    "\n",
    "with st.sidebar:\n",
    "    openai.api_key = st.text_input(\"OpenAI API Key\", value=\"\", type=\"password\")\n",
    "    serper_api_key = st.text_input(\"Serper API Key\", value=\"\", type=\"password\")\n",
    "    num_results = st.number_input(\"Number of Search Results\", min_value=3, max_value=5)\n",
    "    st.caption(\"*Search: Uses Serper & OpenAI APIs, summarizes each search result.*\")\n",
    "    st.caption(\"*URL Lookup: Analyzes a specific URL*\")\n",
    "search_query = st.text_input(\"Search Query\", label_visibility=\"collapsed\")\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "# If the 'Search' button is clicked\n",
    "if col1.button(\"Search\"):\n",
    "    # Validate inputs\n",
    "    if not api_key.strip() or not serper_api_key.strip() or not search_query.strip():\n",
    "        st.error(f\"Please provide the API keys or the missing search terms.\")\n",
    "    else:\n",
    "        try:\n",
    "            with st.spinner(\"Analyzing articles...\"):\n",
    "                # Show the top X relevant news articles from the previous week using Google Serper API\n",
    "                search = GoogleSerperAPIWrapper(type=\"news\", tbs=\"qdr:w1\", serper_api_key=serper_api_key)\n",
    "                result_dict = search.results(search_query)\n",
    "\n",
    "                if not result_dict['news']:\n",
    "                    st.error(f\"No search results for: {search_query}.\")\n",
    "                else:\n",
    "                    for i, item in zip(range(num_results), result_dict['news']):\n",
    "                        url = item.get('link','N/A') \n",
    "                        if url == 'N/A':\n",
    "                            continue  \n",
    "                        loader = WebBaseLoader(url) # bs4 \n",
    "                        try:\n",
    "                            datanews = loader.load()\n",
    "                            overall_chain1 = SequentialChain(chains=[chain1, chain2],\n",
    "                                input_variables=[\"datanews\"],\n",
    "                                output_variables=[\"analysis\"],\n",
    "                                verbose=True)\n",
    "                            first = (overall_chain1({\"datanews\":datanews}))\n",
    "                            st.success(f\"Logical Fallacy Critique: {item['analysis']}\\n\\nLink: {item['link']}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error fetching {item['link']}, exception: {e}\")\n",
    "        except Exception as e:\n",
    "            st.exception(f\"Exception: {e}\")\n",
    "\n",
    "# If 'Search & Summarize' button is clicked\n",
    "if col2.button(\"URL Lookup\"):\n",
    "    # Validate inputs\n",
    "    if not api_key.strip() or not serper_api_key.strip() or not search_query.strip():\n",
    "        st.error(f\"Please provide the API keys or missing URL in the search term window.\")\n",
    "    else:\n",
    "        try:\n",
    "            with st.spinner(\"Analyzing articles...\"):\n",
    "                # Show the top X relevant news articles from the URL entered - lookup since URLs change\n",
    "                search = GoogleSerperAPIWrapper(type=\"news\", tbs=\"qdr:w1\", serper_api_key=serper_api_key)\n",
    "                result_dict = search.results(search_query)\n",
    "\n",
    "                if not result_dict['news']:\n",
    "                    st.error(f\"No search results for: {search_query}.\")\n",
    "                else:\n",
    "                    for i, item in zip(range(num_results), result_dict['news']):\n",
    "                        url = item.get('link','N/A') \n",
    "                        if url == 'N/A':\n",
    "                            continue  \n",
    "                        loader = WebBaseLoader(url) # bs4 \n",
    "                        try:\n",
    "                            datanews = loader.load()\n",
    "                            overall_chain1 = SequentialChain(chains=[chain1, chain2],\n",
    "                                input_variables=[\"datanews\"],\n",
    "                                output_variables=[\"analysis\"],\n",
    "                                verbose=True)\n",
    "                            first = (overall_chain1({\"datanews\":datanews}))\n",
    "                            st.success(f\"Logical Fallacy Critique: {item['analysis']}\\n\\nLink: {item['link']}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error fetching {item['link']}, exception: {e}\")\n",
    "        except Exception as e:\n",
    "            st.exception(f\"Exception: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5716020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc4",
   "language": "python",
   "name": "lc4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
